{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Images and Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read image\n",
    "img = cv.imread('Resources/Photos/cat_large.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read video\n",
    "capture = cv.VideoCapture('Resources/Videos/dog.mp4')\n",
    "while True:\n",
    "    isTrue, frame = capture.read() # read frame by frame\n",
    "    if isTrue:\n",
    "        cv.imshow('Video', frame) # display each frame of the video\n",
    "        if cv.waitKey(20) & 0xFF == ord('d'): # either wait for 20s or the press of the key \"d\", as explained in https://stackoverflow.com/a/52913689/13771347\n",
    "            break\n",
    "    else: # otherwise, -215: assertion failed error\n",
    "        break\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing and Rescaling Images and Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "def rescaleFrame(frame, scale=0.75):\n",
    "    # for Images, Videos and Live Video\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimensions = (width,height)\n",
    "    return cv.resize(frame, dimensions, interpolation=cv.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Videos\n",
    "capture = cv.VideoCapture('Resources/Videos/dog.mp4')\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "\n",
    "    # rescale frame\n",
    "    frame_resized = rescaleFrame(frame, scale=.2) \n",
    "    \n",
    "    cv.imshow('Video', frame)\n",
    "    cv.imshow('Video Resized', frame_resized)\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeRes(width,height):\n",
    "    # only for Live video\n",
    "    capture.set(3,width)\n",
    "    capture.set(4,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Videos\n",
    "capture = cv.VideoCapture('Resources/Videos/dog.mp4')\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "\n",
    "    # rescale frame\n",
    "    frame_resized = changeRes(100,100)) \n",
    "    \n",
    "    cv.imshow('Video', frame)\n",
    "    cv.imshow('Video Resized', frame_resized)\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing Shapes and Placing text on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# blank image\n",
    "blank = np.zeros((500,500,3), dtype='uint8')\n",
    "cv.imshow('Blank', blank)\n",
    "\n",
    "# 1. Paint the image a certain colour\n",
    "blank[200:300, 300:400] = 0,0,255\n",
    "cv.imshow('Red', blank) # BGR\n",
    "\n",
    "# 2. Draw a Rectangle\n",
    "# cv.rectangle(blank, (0,0), (blank.shape[1]//2, blank.shape[0]), (0,255,0), thickness=-1) # filled\n",
    "# cv.rectangle(blank, (0,0), (blank.shape[1]//2, blank.shape[0]), (0,255,0), thickness=cv.FILLED) # filled, equivalent to before\n",
    "cv.rectangle(blank, (0,0), (blank.shape[1]//2, blank.shape[0]), (0,255,0), thickness=2) # not filled\n",
    "cv.imshow('Rectangle', blank)\n",
    "\n",
    "# 3. Draw A circle\n",
    "cv.circle(blank, (blank.shape[1]//2, blank.shape[0]//2), 40, (0,0,255), thickness=-1)\n",
    "cv.imshow('Circle', blank)\n",
    "\n",
    "# 4. Draw a line\n",
    "cv.line(blank, (100,250), (300,400), (255,255,255), thickness=3)\n",
    "cv.imshow('Line', blank)\n",
    "\n",
    "# 5. Write text\n",
    "cv.putText(blank, 'Hello, world!!!', (0,225), cv.FONT_HERSHEY_TRIPLEX, 1.0, (0,255,0), 2)\n",
    "cv.putText(blank, 'Hello!!!', (0,500), cv.FONT_HERSHEY_TRIPLEX, 1.0, (0,255,0), 2)\n",
    "cv.imshow('Text', blank)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Methods in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# Read in an image\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "# Converting to grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# Blur \n",
    "blur = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)\n",
    "cv.imshow('Blur', blur)\n",
    "\n",
    "# Edge Cascade\n",
    "# https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html\n",
    "canny = cv.Canny(blur, 125, 175)\n",
    "cv.imshow('Canny Edges', canny)\n",
    "\n",
    "# Dilating the image\n",
    "# https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html\n",
    "dilated = cv.dilate(canny, (7,7), iterations=3)\n",
    "cv.imshow('Dilated', dilated)\n",
    "\n",
    "# Eroding\n",
    "# https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html\n",
    "eroded = cv.erode(dilated, (7,7), iterations=3)\n",
    "cv.imshow('Eroded', eroded)\n",
    "\n",
    "# Resize\n",
    "resized = cv.resize(img, (500,500), interpolation=cv.INTER_CUBIC)\n",
    "cv.imshow('Resized', resized)\n",
    "\n",
    "# Cropping\n",
    "cropped = img[50:200, 200:400]\n",
    "cv.imshow('Cropped', cropped)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation\n",
    "def translate(img, x, y):\n",
    "    transMat = np.float32([[1,0,x],[0,1,y]])\n",
    "    dimensions = (img.shape[1], img.shape[0])\n",
    "    return cv.warpAffine(img, transMat, dimensions)\n",
    "    \n",
    "# -x --> Left\n",
    "# -y --> Up\n",
    "# x --> Right\n",
    "# y --> Down\n",
    "\n",
    "translated = translate(img, -100, 100)\n",
    "cv.imshow('Translated', translated)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "def rotate(img, angle, rotPoint=None):\n",
    "    (height,width) = img.shape[:2]\n",
    "\n",
    "    if rotPoint is None:\n",
    "        rotPoint = (width//2,height//2)\n",
    "    \n",
    "    rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
    "    dimensions = (width,height)\n",
    "\n",
    "    return cv.warpAffine(img, rotMat, dimensions)\n",
    "\n",
    "rotated = rotate(img, -45)\n",
    "cv.imshow('Rotated', rotated)\n",
    "\n",
    "rotated_rotated = rotate(rotated, -45)\n",
    "cv.imshow('Rotated Rotated', rotated_rotated)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv.resize(img, (500,500), interpolation=cv.INTER_CUBIC)\n",
    "cv.imshow('Resized', resized)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = cv.flip(img, -1)\n",
    "cv.imshow('Flip', flip)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = img[200:400, 300:400]\n",
    "cv.imshow('Cropped', cropped)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contour Detection\n",
    "./Section #1 - Basics/contours.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Spaces \n",
    "RGB, BGR, Grayscale, HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "# BGR to Grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# BGR to HSV\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv.imshow('HSV', hsv)\n",
    "\n",
    "# BGR to RGB\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "cv.imshow('RGB', rgb)\n",
    "\n",
    "# HSV to BGR\n",
    "hsv_bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "cv.imshow('HSV --> BGR', hsv_bgr)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 640, 3)\n",
      "(427, 640)\n",
      "(427, 640)\n",
      "(427, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "\n",
    "cv.imshow('b', b)\n",
    "cv.imshow('g', g)\n",
    "cv.imshow('r', r)\n",
    "\n",
    "blue = cv.merge([b,blank,blank])\n",
    "green = cv.merge([blank,g,blank])\n",
    "red = cv.merge([blank,blank,r])\n",
    "\n",
    "\n",
    "cv.imshow('Blue', blue)\n",
    "cv.imshow('Green', green)\n",
    "cv.imshow('Red', red)\n",
    "\n",
    "print(img.shape)\n",
    "print(b.shape)\n",
    "print(g.shape)\n",
    "print(r.shape)\n",
    "\n",
    "merged = cv.merge([b,g,r])\n",
    "cv.imshow('Merged Image', merged)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros((400,400))+0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring \n",
    "x\n",
    "./Section #2 - Advanced/blurring.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BITWISE operations\n",
    "./Section #2 - Advanced/bitwise.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('Resources/Photos/cats 2.jpg')\n",
    "img2 = cv.imread('Resources/Photos/Park.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv.imshow('Blank Image', blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "\n",
    "weird_shape = cv.bitwise_and(circle,rectangle)\n",
    "cv.imshow('Weird Shape', weird_shape)\n",
    "\n",
    "masked = cv.bitwise_and(img,img2,mask=weird_shape)\n",
    "cv.imshow('Weird Shaped Masked Image', masked)\n",
    "\n",
    "cv.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram \n",
    "./Section #2 - Advanced/histogram.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "./Section #1 - Basics/thresh.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# Laplacian\n",
    "lap = cv.Laplacian(gray, cv.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv.imshow('Laplacian', lap)\n",
    "\n",
    "# Sobel \n",
    "sobelx = cv.Sobel(gray, cv.CV_64F, 1, 0) # Depth is the \"precision\" of each pixel.\n",
    "sobely = cv.Sobel(gray, cv.CV_64F, 0, 1)\n",
    "combined_sobel = cv.bitwise_or(sobelx, sobely)\n",
    "\n",
    "cv.imshow('Sobel X', sobelx)\n",
    "cv.imshow('Sobel Y', sobely)\n",
    "cv.imshow('Combined Sobel', combined_sobel)\n",
    "\n",
    "canny = cv.Canny(gray, 150, 175)\n",
    "cv.imshow('Canny', canny)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection\n",
    "Section #3 - Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning \n",
    "Section #4 - Capstone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('opencv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12c172a89393a56c7a281382e023c70f11150967674928f5eadf41d9a84e83cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
